# ğŸ“Š Data Platform â€“ Chapter Lead Technical Challenge

Plataforma de ingesta de datos con foco en **calidad, trazabilidad y reproducibilidad**, siguiendo buenas prÃ¡cticas de data engineering y backend.

## ğŸ¯ Objetivos

- âœ… Ingesta histÃ³rica (bulk)
- âœ… Validaciones de negocio
- âœ… Integridad referencial
- âœ… Observabilidad y trazabilidad
- âœ… Backup & Recovery
- âœ… MÃ©tricas analÃ­ticas

---

## ğŸ—ï¸ Arquitectura

| Componente | Rol |
|-----------|-----|
| ğŸŒ **FastAPI** | API REST: ingesta, validaciÃ³n, backup/restore |
| ğŸ—„ï¸ **PostgreSQL** | Persistencia relacional con integridad referencial |
| ğŸ³ **Docker Compose** | OrquestaciÃ³n del entorno local |
| ğŸ“ **Filesystem** | `data/` (CSV), `backups/` (AVRO), `sql/` (mÃ©tricas) |

---
---

## ğŸš€ Demo End-to-End

> â„¹ï¸ Todos los comandos estÃ¡n optimizados para **PowerShell**

### 1ï¸âƒ£ Levantar el entorno

```powershell
docker compose up -d --build
```

### 2ï¸âƒ£ Verificar salud del servicio

```powershell
curl.exe http://localhost:8081/health
```

**Respuesta esperada:**
```json
{ "status": "ok" }
```

### 3ï¸âƒ£ Reset de datos (opcional, para demo limpia)

```powershell
docker compose exec db psql -U challenge -d challenge -c `
"TRUNCATE hired_employees, departments, jobs, dq_rejections RESTART IDENTITY CASCADE;"
```

### 4ï¸âƒ£ Ejecutar ingesta histÃ³rica (Bulk Migration)

```powershell
curl.exe -X POST http://localhost:8081/ingest/all
```

**Devuelve:**
- `run_id` de la ejecuciÃ³n
- Registros insertados y rechazados por tabla

### 5ï¸âƒ£ Validar datos cargados

```powershell
# Departments
docker compose exec db psql -U challenge -d challenge -c "SELECT COUNT(*) FROM departments;"

# Jobs
docker compose exec db psql -U challenge -d challenge -c "SELECT COUNT(*) FROM jobs;"

# Employed
docker compose exec db psql -U challenge -d challenge -c "SELECT COUNT(*) FROM hired_employees;"
```

### 6ï¸âƒ£ Revisar Data Quality (rechazos)

```powershell
docker compose exec db psql -U challenge -d challenge -c `
"SELECT reason, COUNT(*) FROM dq_rejections GROUP BY reason;"
```

### 7ï¸âƒ£ Probar API de transacciones (1â€“1000 registros)

```powershell
$body = @{
  table = "departments"
  mode  = "strict"
  rows  = @(
    @{ id = 999; department = "Demo Dept" }
  )
}

Invoke-RestMethod -Method Post `
  -Uri "http://localhost:8081/transactions" `
  -ContentType "application/json" `
  -Body ($body | ConvertTo-Json -Depth 5)
```

### 8ï¸âƒ£ Probar validaciÃ³n de integridad referencial âš ï¸

```powershell
$body = @{
  table = "hired_employees"
  mode  = "strict"
  rows  = @(
    @{
      id = 9999
      name = "Empleado Test"
      datetime = "2021-02-01T10:00:00"
      department_id = 999
      job_id = 999
    }
  )
}

Invoke-RestMethod -Method Post `
  -Uri "http://localhost:8081/transactions" `
  -ContentType "application/json" `
  -Body ($body | ConvertTo-Json -Depth 5)
```

> âŒ Esperado: error de integridad referencial

### 9ï¸âƒ£ Ejecutar mÃ©tricas SQL (Analytics)

```powershell
docker compose exec db psql -U challenge -d challenge -f /sql/metrics.sql
```

**Incluye:**
- ğŸ“Š **MÃ©trica A:** contrataciones por departamento, cargo y trimestre (2021)
- ğŸ“ˆ **MÃ©trica B:** departamentos por encima del promedio de contrataciÃ³n

### ğŸ”Ÿ Generar backup (AVRO)

```powershell
docker compose exec api python src/backup_service.py --table hired_employees
```

**Ver backups:**
```powershell
docker compose exec api ls -la /app/backups
```

### 1ï¸âƒ£1ï¸âƒ£ Restaurar desde backup

```powershell
docker compose exec api python src/backup_service.py `
  --restore `
  --table hired_employees `
  --backup_id <backup_id>
```

### 1ï¸âƒ£2ï¸âƒ£ Revisar logs del servicio

```powershell
docker compose logs --tail=100 api
```

---

## âœ… Lo que se demuestra

| Aspecto | Status |
|--------|--------|
| Ingesta histÃ³rica | âœ“ |
| Data Quality | âœ“ |
| API transaccional | âœ“ |
| Integridad referencial | âœ“ |
| MÃ©tricas SQL | âœ“ |
| Backup & Recovery | âœ“ |
| Observabilidad | âœ“ |
---

## ğŸš€ Roadmap: EvoluciÃ³n y Escalabilidad

La soluciÃ³n actual cubre el alcance del challenge, pero contempla una **evoluciÃ³n natural** para mayores volÃºmenes.

### ğŸ“ˆ Si el volumen aumenta...

#### **Procesamiento: Pandas â†’ Polars**
- ğŸ”€ EjecuciÃ³n paralela nativa
- ğŸ’¾ Menor consumo de memoria (Apache Arrow)
- ğŸ”§ Transparente para la lÃ³gica de negocio

#### **Desacoplamiento: API â†” Ingesta Batch**
```
Arquitectura Actual:        API + Ingesta Batch (acoplado)
                â†“
Arquitectura Escalable:     API (transacciones) + Jobs async (ingesta pesada)
```

**Ventajas:**
- ParalelizaciÃ³n
- Reintentos controlados
- Independencia de ciclos

#### **Infraestructura: On-Prem â†’ Cloud-Native (GCP)**
- â˜ï¸ **Storage:** Cloud Storage (inmutable, versionado)
- ğŸƒ **ComputaciÃ³n:** Cloud Functions / Cloud Run
- ğŸ“Š **Analytics:** BigQuery con proyecciones
- ğŸ” **Data Quality:** Mantiene trazabilidad y `run_id`

**Invariantes:** La Data Quality, versionado y auditorÃ­a se mantienen intactos.